{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习入门与Pytorch|3.2 在jupyter中实现各种梯度算法动画\n",
    "\n",
    "ref:\n",
    "https://zhuanlan.zhihu.com/p/416705845?utm_id=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker, cm\n",
    "import seaborn as sns\n",
    "from ipywidgets import *\n",
    "import math\n",
    "\n",
    "sns.set_context('paper', font_scale=2)\n",
    "sns.set_style('ticks')\n",
    "\n",
    "def f_2d(x1, x2):\n",
    "    '''original function to minimize'''\n",
    "    return x1 ** 2 +  x2 ** 2\n",
    "\n",
    "def f_grad(x1, x2):\n",
    "    '''the gradient dfdx1 and dfdx2'''\n",
    "    dfdx1 = 0.2 * x1\n",
    "    dfdx2 = 4 * x2\n",
    "    return dfdx1, dfdx2\n",
    "\n",
    "def train_2d(trainer, lr):\n",
    "    \"\"\"Train a 2d object function with a customized trainer\"\"\"\n",
    "    x1, x2 = -5, -2\n",
    "    s_x1, s_x2 = 0, 0\n",
    "    res = [(x1, x2)]\n",
    "    for i in range(50):\n",
    "        x1, x2, s_x1, s_x2, lr = trainer(x1, x2, s_x1, s_x2, lr)\n",
    "        res.append((x1, x2))\n",
    "    return res\n",
    "\n",
    "def plot_2d(res, figsize=(10, 6), title=None):\n",
    "    x1_, x2_ = zip(*res)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.plot([0], [0], 'r*', ms=15)\n",
    "    plt.text(0.0, 0.25, 'minimum', color='w')\n",
    "    plt.plot(x1_[0], x2_[0], 'ro', ms=10)\n",
    "    plt.text(x1_[0]+0.1, x2_[0]+0.2, 'start', color='w')\n",
    "    plt.plot(x1_, x2_, '-o', color='#ff7f0e')\n",
    " \n",
    "    plt.plot(x1_[-1], x2_[-1], 'wo')\n",
    "    plt.text(x1_[-1], x2_[-1]-0.25, 'end', color='w')\n",
    "    x1 = np.linspace(-5.5, 3, 50)\n",
    "    x2 = np.linspace(min(-3.0, min(x2_) - 1), max(3.0, max(x2_) + 1), 100)\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "    plt.contourf(x1, x2, f_2d(x1, x2), cmap='rainbow')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始的梯度下降SGD\n",
    "\n",
    "迭代公式\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "如下图，显然，学习率过小，则在指定迭代步长下损失函数可能会无法收敛至最小值；随着学习率的升高，在极小值处会越来越容易发生震荡，震荡幅度也会越来越大；最后当学习率过大，则可能会导致损失函数发散。\n",
    "\n",
    "如果是在神经网络训练中出现了NaN，要考虑是否是学习率过大导致的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b1453928e74737a69aa1b32e0d32d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.05, description='lr', max=1.0, step=0.001), Output()), _dom_classes=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sgd(x1, x2, s1, s2, lr):\n",
    "    dfdx1, dfdx2 = f_grad(x1, x2)\n",
    "    return (x1 - lr * dfdx1, x2 - lr * dfdx2, 0, 0, lr)\n",
    "\n",
    "@interact(lr=(0, 1, 0.001))\n",
    "def visualize_gradient_descent(lr=0.05):\n",
    "    res = train_2d(sgd, lr)\n",
    "    plot_2d(res, title='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 带动量（momentum）的梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263ecb7e4e1c40e4a4fefaa310af2c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lr', max=0.99, step=0.001), FloatSlider(value=0.1, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(lr=(0, 0.99, 0.001), gamma=(0, 0.99, 0.001),\n",
    "         continuous_update=False)\n",
    "def visualize_sgd_momentum(lr=0.1, gamma=0.1):\n",
    "    '''lr: learning rate\n",
    "    gamma: parameter for momentum sgd'''\n",
    " \n",
    "    def momentum(x1, x2, v1, v2, lr):\n",
    "        dfdx1, dfdx2 = f_grad(x1, x2)\n",
    "        v1 = gamma * v1 + lr * dfdx1\n",
    "        v2 = gamma * v2 + lr * dfdx2\n",
    "        x1 = x1 - v1\n",
    "        x2 = x2 - v2\n",
    "        return (x1, x2, v1, v2, lr)\n",
    " \n",
    "    res = train_2d(momentum, lr)\n",
    "    plot_2d(res, title='momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带惯性的梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7700650066e948308bbcda76a573bb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lr', max=0.99, step=0.01), FloatSlider(value=0.1, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(lr=(0, 0.99, 0.01), gamma=(0, 0.99, 0.01),\n",
    "          continuous_update=False)\n",
    "def visualize_sgd_inertia(lr=0.1, gamma=0.1):\n",
    "    '''lr: learning rate\n",
    "    gamma: parameter for inertia sgd'''\n",
    " \n",
    "    def inertia(x1, x2, v1, v2, lr):\n",
    "        dfdx1, dfdx2 = f_grad(x1, x2)\n",
    "        v1 = gamma * v1 + (1 - gamma) * dfdx1\n",
    "        v2 = gamma * v2 + (1 - gamma) * dfdx2\n",
    "        x1 = x1 - lr * v1\n",
    "        x2 = x2 - lr * v2\n",
    "        return (x1, x2, v1, v2, lr)\n",
    " \n",
    "    res = train_2d(inertia, lr)\n",
    "    plot_2d(res, title='inertia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自适应梯度下降Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d923626c1094d1482deb83798bcf68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lr', max=4.0, step=0.01), Output()), _dom_classes=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(lr=(0, 4, 0.01),\n",
    "          continuous_update=False)\n",
    "def visualize_adagrad(lr=0.1):\n",
    "    '''lr: learning rate'''\n",
    "    def adagrad_2d(x1, x2, s1, s2, lr):\n",
    "        g1, g2 = f_grad(x1, x2)\n",
    "        eps = 1e-6\n",
    "        s1 += g1 ** 2\n",
    "        s2 += g2 ** 2\n",
    "        x1 -= lr / math.sqrt(s1 + eps) * g1\n",
    "        x2 -= lr / math.sqrt(s2 + eps) * g2\n",
    "        return x1, x2, s1, s2, lr\n",
    " \n",
    "    res = train_2d(adagrad_2d, lr)\n",
    "    plot_2d(res, title='adagrad')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp算法（AdaDelta）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef63f8e4a4e4c18a9dbf5828f5c479e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lr', max=1.0, step=0.001), FloatSlider(value=0.9, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(lr=(0, 1, 0.001), \n",
    "          gamma=(0, 0.99, 0.001),\n",
    "          continuous_update=False)\n",
    "def visualize_rmsprop(lr=0.1, gamma=0.9):\n",
    "    '''lr: learning rate, \n",
    "       gamma: momentum'''  \n",
    "    def rmsprop_2d(x1, x2, s1, s2, lr):\n",
    "        eps = 1e-6\n",
    "        g1, g2 = f_grad(x1, x2)\n",
    "        s1 = gamma * s1 + (1 - gamma) * g1 ** 2\n",
    "        s2 = gamma * s2 + (1 - gamma) * g2 ** 2\n",
    "        x1 -= lr / math.sqrt(s1 + eps) * g1\n",
    "        x2 -= lr / math.sqrt(s2 + eps) * g2\n",
    "        return x1, x2, s1, s2, lr\n",
    "\n",
    "    res = train_2d(rmsprop_2d, lr)\n",
    "    plot_2d(res, title='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594da959ca1042f7a4d95e349a3bf915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lr', max=1.0, step=0.001), FloatSlider(value=0.9, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(lr=(0, 1, 0.001), \n",
    "          beta1=(0, 0.999, 0.001),\n",
    "          beta2=(0, 0.999, 0.001),\n",
    "          continuous_update=False)\n",
    "def visualize_adam(lr=0.1, beta1=0.9, beta2=0.999):\n",
    "    '''lr: learning rate\n",
    "    beta1: parameter for E(g)\n",
    "    beta2: parameter for E(g^2)\n",
    "    '''  \n",
    "    def Deltax(m, n, g, t):\n",
    "        eps = 1.0E-6\n",
    "        m = beta1 * m + (1 - beta1) * g\n",
    "        n = beta2 * n + (1 - beta2) * g*g\n",
    "        m_hat = m / (1 - beta1**t)\n",
    "        n_hat = n / (1 - beta2**t)\n",
    "        dx = lr * m_hat / (math.sqrt(n_hat) + eps)\n",
    "        return m, n, dx\n",
    " \n",
    "    def adam_2d(x1, x2, m1, n1, m2, n2, lr, t):\n",
    "        '''m1, m2: E(g1), E(g2)\n",
    "           n1, n2: E(g1^2), E(g2^2) where E() is expectation\n",
    "           lr: learning rate\n",
    "           t: time step'''\n",
    "        eps = 1e-6\n",
    "        g1, g2 = f_grad(x1, x2)\n",
    "        m1, n1, dx1 = Deltax(m1, n1, g1, t)\n",
    "        m2, n2, dx2 = Deltax(m2, n2, g2, t)       \n",
    "        x1 -= dx1\n",
    "        x2 -= dx2\n",
    "        return x1, x2, m1, n1, m2, n2, lr\n",
    " \n",
    "    def train_adam(trainer, lr):\n",
    "        \"\"\"Train a 2d object function with a customized trainer\"\"\"\n",
    "        x1, x2 = -5, -2\n",
    "        m1, n1, m2, n2 = 0, 0, 0, 0\n",
    "        res = [(x1, x2)]\n",
    "        for i in range(30):\n",
    "            x1, x2, m1, n1, m2, n2, lr = trainer(x1, x2, m1, n1, m2, n2, lr, i+1)\n",
    "            res.append((x1, x2))\n",
    "        return res\n",
    " \n",
    "    res = train_adam(adam_2d, lr)\n",
    "    plot_2d(res, title='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
